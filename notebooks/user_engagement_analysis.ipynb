{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "8509fbb3be675dff6dc11c9c2ee7ff0c3d019cfe731b4fd2ce5e1b4c5a166295"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Loading data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading file function\n",
    "def load_csv(path):\n",
    "    df = pd.read_csv(path,engine='python',error_bad_lines=False, na_values=['?', None,'-','--','undefined'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaded file\n",
    "df= load_csv('../data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Bearer Id            Start  Start ms              End  End ms  \\\n",
       "0  1.311448e+19   4/4/2019 12:01     770.0  4/25/2019 14:35   662.0   \n",
       "1  1.311448e+19   4/9/2019 13:04     235.0   4/25/2019 8:15   606.0   \n",
       "2  1.311448e+19   4/9/2019 17:42       1.0  4/25/2019 11:58   652.0   \n",
       "3  1.311448e+19   4/10/2019 0:31     486.0   4/25/2019 7:36   171.0   \n",
       "4  1.311448e+19  4/12/2019 20:10     565.0  4/25/2019 10:40   954.0   \n",
       "\n",
       "   Dur. (ms)          IMSI  MSISDN/Number          IMEI  \\\n",
       "0  1823652.0  2.082014e+14   3.366496e+10  3.552121e+13   \n",
       "1  1365104.0  2.082019e+14   3.368185e+10  3.579401e+13   \n",
       "2  1361762.0  2.082003e+14   3.376063e+10  3.528151e+13   \n",
       "3  1321509.0  2.082014e+14   3.375034e+10  3.535661e+13   \n",
       "4  1089009.0  2.082014e+14   3.369980e+10  3.540701e+13   \n",
       "\n",
       "      Last Location Name  ...  Youtube DL (Bytes)  Youtube UL (Bytes)  \\\n",
       "0  9.16456699548519E+015  ...          15854611.0           2501332.0   \n",
       "1                L77566A  ...          20247395.0          19111729.0   \n",
       "2                D42335A  ...          19725661.0          14699576.0   \n",
       "3                T21824A  ...          21388122.0          15146643.0   \n",
       "4                D88865A  ...          15259380.0          18962873.0   \n",
       "\n",
       "   Netflix DL (Bytes)  Netflix UL (Bytes)  Gaming DL (Bytes)  \\\n",
       "0           8198936.0           9656251.0        278082303.0   \n",
       "1          18338413.0          17227132.0        608750074.0   \n",
       "2          17587794.0           6163408.0        229584621.0   \n",
       "3          13994646.0           1097942.0        799538153.0   \n",
       "4          17124581.0            415218.0        527707248.0   \n",
       "\n",
       "   Gaming UL (Bytes)  Other DL (Bytes)  Other UL (Bytes)  Total UL (Bytes)  \\\n",
       "0         14344150.0       171744450.0         8814393.0        36749741.0   \n",
       "1          1170709.0       526904238.0        15055145.0        53800391.0   \n",
       "2           395630.0       410692588.0         4215763.0        27883638.0   \n",
       "3         10849722.0       749039933.0        12797283.0        43324218.0   \n",
       "4          3529801.0       550709500.0        13910322.0        38542814.0   \n",
       "\n",
       "   Total DL (Bytes)  \n",
       "0       308879636.0  \n",
       "1       653384965.0  \n",
       "2       279807335.0  \n",
       "3       846028530.0  \n",
       "4       569138589.0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Bearer Id</th>\n      <th>Start</th>\n      <th>Start ms</th>\n      <th>End</th>\n      <th>End ms</th>\n      <th>Dur. (ms)</th>\n      <th>IMSI</th>\n      <th>MSISDN/Number</th>\n      <th>IMEI</th>\n      <th>Last Location Name</th>\n      <th>...</th>\n      <th>Youtube DL (Bytes)</th>\n      <th>Youtube UL (Bytes)</th>\n      <th>Netflix DL (Bytes)</th>\n      <th>Netflix UL (Bytes)</th>\n      <th>Gaming DL (Bytes)</th>\n      <th>Gaming UL (Bytes)</th>\n      <th>Other DL (Bytes)</th>\n      <th>Other UL (Bytes)</th>\n      <th>Total UL (Bytes)</th>\n      <th>Total DL (Bytes)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.311448e+19</td>\n      <td>4/4/2019 12:01</td>\n      <td>770.0</td>\n      <td>4/25/2019 14:35</td>\n      <td>662.0</td>\n      <td>1823652.0</td>\n      <td>2.082014e+14</td>\n      <td>3.366496e+10</td>\n      <td>3.552121e+13</td>\n      <td>9.16456699548519E+015</td>\n      <td>...</td>\n      <td>15854611.0</td>\n      <td>2501332.0</td>\n      <td>8198936.0</td>\n      <td>9656251.0</td>\n      <td>278082303.0</td>\n      <td>14344150.0</td>\n      <td>171744450.0</td>\n      <td>8814393.0</td>\n      <td>36749741.0</td>\n      <td>308879636.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.311448e+19</td>\n      <td>4/9/2019 13:04</td>\n      <td>235.0</td>\n      <td>4/25/2019 8:15</td>\n      <td>606.0</td>\n      <td>1365104.0</td>\n      <td>2.082019e+14</td>\n      <td>3.368185e+10</td>\n      <td>3.579401e+13</td>\n      <td>L77566A</td>\n      <td>...</td>\n      <td>20247395.0</td>\n      <td>19111729.0</td>\n      <td>18338413.0</td>\n      <td>17227132.0</td>\n      <td>608750074.0</td>\n      <td>1170709.0</td>\n      <td>526904238.0</td>\n      <td>15055145.0</td>\n      <td>53800391.0</td>\n      <td>653384965.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.311448e+19</td>\n      <td>4/9/2019 17:42</td>\n      <td>1.0</td>\n      <td>4/25/2019 11:58</td>\n      <td>652.0</td>\n      <td>1361762.0</td>\n      <td>2.082003e+14</td>\n      <td>3.376063e+10</td>\n      <td>3.528151e+13</td>\n      <td>D42335A</td>\n      <td>...</td>\n      <td>19725661.0</td>\n      <td>14699576.0</td>\n      <td>17587794.0</td>\n      <td>6163408.0</td>\n      <td>229584621.0</td>\n      <td>395630.0</td>\n      <td>410692588.0</td>\n      <td>4215763.0</td>\n      <td>27883638.0</td>\n      <td>279807335.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.311448e+19</td>\n      <td>4/10/2019 0:31</td>\n      <td>486.0</td>\n      <td>4/25/2019 7:36</td>\n      <td>171.0</td>\n      <td>1321509.0</td>\n      <td>2.082014e+14</td>\n      <td>3.375034e+10</td>\n      <td>3.535661e+13</td>\n      <td>T21824A</td>\n      <td>...</td>\n      <td>21388122.0</td>\n      <td>15146643.0</td>\n      <td>13994646.0</td>\n      <td>1097942.0</td>\n      <td>799538153.0</td>\n      <td>10849722.0</td>\n      <td>749039933.0</td>\n      <td>12797283.0</td>\n      <td>43324218.0</td>\n      <td>846028530.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.311448e+19</td>\n      <td>4/12/2019 20:10</td>\n      <td>565.0</td>\n      <td>4/25/2019 10:40</td>\n      <td>954.0</td>\n      <td>1089009.0</td>\n      <td>2.082014e+14</td>\n      <td>3.369980e+10</td>\n      <td>3.540701e+13</td>\n      <td>D88865A</td>\n      <td>...</td>\n      <td>15259380.0</td>\n      <td>18962873.0</td>\n      <td>17124581.0</td>\n      <td>415218.0</td>\n      <td>527707248.0</td>\n      <td>3529801.0</td>\n      <td>550709500.0</td>\n      <td>13910322.0</td>\n      <td>38542814.0</td>\n      <td>569138589.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 55 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for fill missing values\n",
    "def fill_missing_values(df):\n",
    "    \"\"\" This function fill the missing values \n",
    "        of columns with object datatype using \n",
    "        mode and columns with numeric datatypes\n",
    "        with median\"\"\"\n",
    "    objectTypeCols = [col_name for col_name in df.columns.tolist() if df.dtypes[col_name] == object]\n",
    "    numericTypeCols = [col_name for col_name in df.columns.tolist() if col_name not in objectTypeCols]\n",
    "    print(objectTypeCols)\n",
    "\n",
    "    #for object type columns use mode\n",
    "    for col in objectTypeCols:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    \n",
    "    #for numeric type columsn use median\n",
    "    for col in numericTypeCols:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Handle_missing_values(df):\n",
    "        \"\"\" This function handles missing values\n",
    "            by removing columns with more than 30%\n",
    "            null values and filling others\"\"\"\n",
    "\n",
    "        # removed columns containing null values of more than 30%\n",
    "        row,col = df.shape\n",
    "        df.dropna(axis='columns',thresh=row*0.7,inplace=True)\n",
    "        # for columns still with missing values fill appropriately\n",
    "        df = fill_missing_values(df)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Start', 'End', 'Last Location Name', 'Handset Manufacturer', 'Handset Type']\n"
     ]
    }
   ],
   "source": [
    "cleaned_data = Handle_missing_values(df)"
   ]
  },
  {
   "source": [
    "after loading and cleaning the data now we will do our eda on User engagement, to understand how well the users engage on the available applications. We need to determine the level of engagement of a random user for any application. To do that we will focus on the following \"sessions frequency\", \"the duration of the session\" and \"the sessions total traffic (download and upload (bytes))\". We will do analysis on these variables, normalize them and then cluster users using these metrics, so it will be easier to provide a more customized service for each user.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "First step is Doing EDA on the variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Top 10 users with high session frequency\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MSISDN/Number\n",
       "3.366371e+10    1067\n",
       "3.362632e+10      18\n",
       "3.361489e+10      17\n",
       "3.362578e+10      17\n",
       "3.365973e+10      16\n",
       "3.367588e+10      15\n",
       "3.376054e+10      15\n",
       "3.366716e+10      13\n",
       "3.362708e+10      12\n",
       "3.360452e+10      12\n",
       "Name: Bearer Id, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "# print out unique session counts per person\n",
    "# unique_sessions = {\"unique_session_counts\":cleaned_data.groupby(\"MSISDN/Number\").nunique(), \"Out of\": cleaned_data[\"Bearer Id\"].count()}\n",
    "\n",
    "# groups users based on their MSIDN number and count how many sessions they created\n",
    "cleaned_copy = cleaned_data.copy()\n",
    "cleaned_copy['total data(bytes)'] = cleaned_copy['Total UL (Bytes)'] + cleaned_copy ['Total DL (Bytes)']\n",
    "df_user = cleaned_copy.groupby(\"MSISDN/Number\")\n",
    "\n",
    "# print(unique_sessions)\n",
    "df_session_freq = df_user[\"Bearer Id\"].count().sort_values(ascending=False)\n",
    "df_session_dur = df_user[\"Dur. (ms)\"].sum().sort_values(ascending=False)\n",
    "df_session_data = df_user[\"total data(bytes)\"].sum().sort_values(ascending=False)\n",
    "\n",
    "print(\"Top 10 users with high session frequency\")\n",
    "df_session_freq.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Top 10 users with high session duration\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MSISDN/Number\n",
       "3.366371e+10    72655568.0\n",
       "3.362578e+10    18553754.0\n",
       "3.361489e+10     9966898.0\n",
       "3.376054e+10     9279434.0\n",
       "3.362632e+10     8791927.0\n",
       "3.366716e+10     8744914.0\n",
       "3.366284e+10     6614270.0\n",
       "3.366469e+10     6288730.0\n",
       "3.360313e+10     6287761.0\n",
       "3.366746e+10     5649882.0\n",
       "Name: Dur. (ms), dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "# duration of sessions per user\n",
    "print(\"Top 10 users with high session duration\")\n",
    "df_session_dur.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Top 10 users with high data volume\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MSISDN/Number\n",
       "3.366371e+10    5.319636e+11\n",
       "3.361489e+10    8.846226e+09\n",
       "3.376054e+10    8.514774e+09\n",
       "3.362578e+10    8.499621e+09\n",
       "3.362632e+10    7.971167e+09\n",
       "3.367588e+10    7.891111e+09\n",
       "3.365973e+10    7.705863e+09\n",
       "3.366646e+10    7.308501e+09\n",
       "3.376041e+10    7.132371e+09\n",
       "3.366471e+10    6.872018e+09\n",
       "Name: total data(bytes), dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "# total data volume per user\n",
    "print(\"Top 10 users with high data volume\")\n",
    "df_session_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}